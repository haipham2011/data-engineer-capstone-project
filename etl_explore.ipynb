{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/19 10:13:47 WARN Utils: Your hostname, Hais-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.31.78 instead (on interface en0)\n",
      "23/03/19 10:13:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/19 10:13:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initial Spark\n",
    "\n",
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"main\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input directory\n",
    "INPUT_PATH = \"<input_your_input_data_path_here>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n",
      "Number of rows in zone table: 265\n"
     ]
    }
   ],
   "source": [
    "# Read zone lookup csv file\n",
    "df_zone = spark.read.option(\"header\", True).csv(f\"{INPUT_PATH}/taxi_zones_lookup.csv\")\n",
    "df_zone.createOrReplaceTempView(\"zoneTable\")\n",
    "df_zone.printSchema()\n",
    "print(f\"Number of rows in zone table: {df_zone.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n",
      "Number of rows in trip table: 7696617\n"
     ]
    }
   ],
   "source": [
    "# Read taxi parquet files\n",
    "df_trip = spark.read.parquet(f\"{INPUT_PATH}/yellow_tripdata_2019-01.parquet\")\n",
    "df_trip.createOrReplaceTempView(\"taxiTable\")\n",
    "df_trip.printSchema()\n",
    "print(f\"Number of rows in trip table: {df_trip.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_id: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n",
      "+-----------+-------+--------------+------------+\n",
      "|location_id|borough|          zone|service_zone|\n",
      "+-----------+-------+--------------+------------+\n",
      "|          1|    EWR|Newark Airport|         EWR|\n",
      "+-----------+-------+--------------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean up zone table column names\n",
    "\n",
    "df_zone = df_zone.withColumnRenamed(\"LocationID\", \"location_id\") \\\n",
    "                    .withColumnRenamed(\"Borough\", \"borough\") \\\n",
    "                    .withColumnRenamed(\"Zone\", \"zone\").dropna()\n",
    "\n",
    "df_zone.printSchema()\n",
    "df_zone.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_id: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rate_code_id: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pick_up_location_id: long (nullable = true)\n",
      " |-- drop_off_location_id: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      " |-- uuid: string (nullable = false)\n",
      "\n",
      "+---------+--------------------+---------------------+---------------+-------------+------------+------------------+-------------------+--------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+\n",
      "|vendor_id|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|rate_code_id|store_and_fwd_flag|pick_up_location_id|drop_off_location_id|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|                uuid|\n",
      "+---------+--------------------+---------------------+---------------+-------------+------------+------------------+-------------------+--------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+\n",
      "|        1| 2019-01-01 02:46:40|  2019-01-01 02:53:20|              1|          1.5|         1.0|                 N|                151|                 239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|       null|92886142-446c-42f...|\n",
      "+---------+--------------------+---------------------+---------------+-------------+------------+------------------+-------------------+--------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean up trip table column names\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "df_trip = df_trip.withColumn(\"uuid\", f.expr(\"uuid()\")).withColumnRenamed(\"VendorId\", \"vendor_id\") \\\n",
    "                        .withColumnRenamed(\"Passenger_count\", \"passenger_count\") \\\n",
    "                        .withColumnRenamed(\"Trip_distance\", \"trip_distance\") \\\n",
    "                        .withColumnRenamed(\"PULocationID\",\"pick_up_location_id\") \\\n",
    "                        .withColumnRenamed(\"DOLocationID\",\"drop_off_location_id\") \\\n",
    "                        .withColumnRenamed(\"RateCodeID\",\"rate_code_id\") \\\n",
    "                        .withColumnRenamed(\"Store_and_fwd_flag\",\"store_and_fwd_flag\") \\\n",
    "                        .withColumnRenamed(\"Payment_type\",\"payment_type\") \\\n",
    "                        .withColumnRenamed(\"Fare_amount\",\"fare_amount\") \\\n",
    "                        .withColumnRenamed(\"Extra\",\"extra\") \\\n",
    "                        .withColumnRenamed(\"MTA_tax\",\"mta_tax\") \\\n",
    "                        .withColumnRenamed(\"Improvement_surcharge\",\"improvement_surcharge\") \\\n",
    "                        .withColumnRenamed(\"Tip_amount\",\"tip_amount\") \\\n",
    "                        .withColumnRenamed(\"Tolls_amount\",\"tolls_amount\") \\\n",
    "                        .withColumnRenamed(\"Total_amount\",\"total_amount\") \\\n",
    "                        .withColumnRenamed(\"Congestion_Surcharge\",\"congestion_surcharge\") \\\n",
    "                        .withColumnRenamed(\"Airport_fee\",\"airport_fee\") \\\n",
    "                        .withColumn(\"passenger_count\", f.col(\"passenger_count\").cast(t.LongType()))\n",
    "df_trip.printSchema()\n",
    "df_trip.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+---+----+------+------+-----------+\n",
      "|          timestamp|year|month|day|hour|minute|second|day_of_week|\n",
      "+-------------------+----+-----+---+----+------+------+-----------+\n",
      "|2019-01-01 02:46:40|2019|    1|  1|   2|    46|    40|          3|\n",
      "+-------------------+----+-----+---+----+------+------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create date table from tpep_pickup_datetime\n",
    "df_date = df_trip.select(f.col(\"tpep_pickup_datetime\")) \\\n",
    "                .withColumnRenamed(\"tpep_pickup_datetime\", \"timestamp\") \\\n",
    "                .withColumn(\"year\", f.year(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"month\", f.month(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"day\", f.dayofmonth(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"hour\", f.hour(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"minute\", f.minute(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"second\", f.second(f.col(\"timestamp\"))) \\\n",
    "                .withColumn(\"day_of_week\", f.dayofweek(f.col(\"timestamp\")))\n",
    "\n",
    "df_date.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick up location gain table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "|total_fare_amount|total_extra|total_mta_tax|  total_tip_amount|total_tolls_amount|          zone|location_id|\n",
      "+-----------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "| 7225.38999999999|     174.75|        135.5|            226.16| 295.4799999999998|Brighton Beach|         29|\n",
      "|18777.30000000003|      447.5|        376.5|104.55999999999997| 712.4399999999991|  Borough Park|         26|\n",
      "+-----------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Drop off location gain table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:===================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "| total_fare_amount|total_extra|total_mta_tax|  total_tip_amount|total_tolls_amount|          zone|location_id|\n",
      "+------------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "| 91443.14999999995|    1136.25|       1192.0| 4649.979999999999| 3225.010000000037|  Borough Park|         26|\n",
      "|45342.759999999995|      536.0|        512.5|2450.4899999999984| 1502.959999999998|Brighton Beach|         29|\n",
      "+------------------+-----------+-------------+------------------+------------------+--------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create pickup_location_gain table\n",
    "def create_location_gain_table(df_trip: DataFrame, df_zone: DataFrame, type_location: str) -> DataFrame:\n",
    "    df_location_gain = df_trip.select(f.col(type_location), \n",
    "                                  f.col(\"fare_amount\"), f.col(\"extra\"), f.col(\"mta_tax\"), \n",
    "                                  f.col(\"tip_amount\"), f.col(\"tolls_amount\"), f.col(\"total_amount\")) \\\n",
    "                                    .groupBy(type_location).agg(f.sum(\"fare_amount\").alias(\"total_fare_amount\"), \n",
    "                                                                f.sum(\"extra\").alias(\"total_extra\"),\n",
    "                                                                f.sum(\"mta_tax\").alias(\"total_mta_tax\"),\n",
    "                                                                f.sum(\"tip_amount\").alias(\"total_tip_amount\"),\n",
    "                                                                f.sum(\"tolls_amount\").alias(\"total_tolls_amount\"))\n",
    "\n",
    "    df_zone_simplified = df_zone.select(f.col(\"zone\"), f.col(\"location_id\"))\n",
    "    df_location_gain = df_location_gain.join(df_zone_simplified) \\\n",
    "                        .where(df_zone_simplified[\"location_id\"] == df_location_gain[type_location]) \\\n",
    "                        .drop(type_location)\n",
    "    \n",
    "    return df_location_gain\n",
    "\n",
    "                        \n",
    "df_pu_location_gain = create_location_gain_table(df_trip, df_zone, \"pick_up_location_id\")\n",
    "df_do_location_gain = create_location_gain_table(df_trip, df_zone, \"drop_off_location_id\")\n",
    "\n",
    "print(\"Pick up location gain table\")\n",
    "df_pu_location_gain.show(2)\n",
    "\n",
    "print(\"Drop off location gain table\")\n",
    "df_do_location_gain.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "23/03/20 01:48:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "+-----------+---------------------+--------------------+\n",
      "|day_of_week|total_passenger_count| total_trip_distance|\n",
      "+-----------+---------------------+--------------------+\n",
      "|          1|              6098684|1.0596457629999993E7|\n",
      "|          6|              8222560|1.4551210489999823E7|\n",
      "+-----------+---------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create daily passenger/distance table\n",
    "\n",
    "df_trip_date = df_trip.join(df_date).where(df_trip[\"tpep_pickup_datetime\"] == df_date[\"timestamp\"]) \\\n",
    "                    .select(f.col(\"day_of_week\"), f.col(\"passenger_count\"), f.col(\"trip_distance\")).dropna()\n",
    "                            \n",
    "df_daily_passenger = df_trip_date.groupBy(\"day_of_week\").agg(f.sum(\"passenger_count\").alias(\"total_passenger_count\"),\n",
    "                                                             f.sum(\"trip_distance\").alias(\"total_trip_distance\"))\n",
    "df_daily_passenger.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cd7ed9539daae80e1c5522a995401b95f90b3ce5b55a95355dc41e6f454803c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
